# TODO: add papers by configuration file
base_url: "https://arxiv.paperswithcode.com/api/v0/papers/"
# =========================================================
# 请确保这里是您的用户名和仓库名
# =========================================================
user_name: "liu-s-q19"
repo_name: "RL4LLM-arxiv-daily"

show_authors: True
show_links: True
show_badge: True
max_results: 15

publish_readme: True
publish_gitpage: True
publish_wechat: False

# file paths
json_readme_path: './docs/cv-arxiv-daily.json'
json_gitpage_path: './docs/cv-arxiv-daily-web.json'
json_wechat_path: './docs/cv-arxiv-daily-wechat.json'

md_readme_path: 'README.md'
md_gitpage_path: './docs/index.md'
md_wechat_path: './docs/wechat.md'

# keywords to search
# 修改说明：使用了 - 符号列表格式，彻底解决 parsing error
keywords:
  "LLM RL Algorithms":
    filters:
      - "Group Relative Policy Optimization"
      - "GRPO"
      - "DAPO"
      - "GSPO"
  # === 2. RL + LLM 的各种组合 (考虑缩写 RL 和全称) ===
      # 基准: Reinforcement Learning with LLMs
      - "Reinforcement Learning with LLM"
      - "Reinforcement Learning for LLM"
      - "RL with LLM"
      - "RL for LLM"
      - "LLM Reinforcement Learning"
      - "Large Language Model Reinforcement Learning"
      
      # === 3. RL + Reasoning 的各种组合 (推理能力的 RL) ===
      # 基准: Reinforcement Learning for Reasoning Language Models / LLM Reasoning
      - "Reinforcement Learning for Reasoning"
      - "RL for Reasoning"
      - "Reasoning with Reinforcement Learning"
      - "Reasoning with RL"
      - "LLM Reasoning with RL"


  "Reasoning & RLVR":
    filters:
      - "Process Reward"
      - "Verifiable Reward"
      - "Outcome Reward"
      - "Self-Correction"
      - "Chain of Thought"
      - "System 2 Reasoning"

  "RL for Auto-Driving":
    filters:
      - "Vision Language Action"
      - "VLA"
      - "End-to-end Driving"
      - "World Model"
      - "Autonomous Driving"
      - "Embodied AI"
